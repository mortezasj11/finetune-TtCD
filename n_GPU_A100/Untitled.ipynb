{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af230067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchdata\n",
      "  Downloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 KB\u001b[0m \u001b[31m7.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=2 in /.local/lib/python3.10/site-packages (from torchdata) (2.0.0+cu117)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.18.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2->torchdata) (4.0.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2->torchdata) (18.1.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "Installing collected packages: torchdata\n",
      "Successfully installed torchdata-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata   # only rank 0 needs to do this the first time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360c6dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test', 'train', 'val'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_path=\"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv\"\n",
    " \n",
    "df=pd.read_csv(csv_path)#.query(\"split == 'train'\")\n",
    "set(df[\"split\"].to_list())# {'test', 'train', 'val'}\n",
    "I wanna save a nlst_event_train_val_ in a way that all rows with split of val changes to split of train , and the test one changes to val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4feacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val', 'train'}\n",
      "Saved remapped splits to /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Remap splits: val→train, test→val (train stays train)\n",
    "df['split'] = df['split'].replace({\n",
    "    'val':   'train',\n",
    "    'test':  'val'\n",
    "})\n",
    "\n",
    "# 3. (Optional) Check you only have 'train' and 'val' now\n",
    "print(set(df['split']))  # -> {'train', 'val'}\n",
    "\n",
    "# 4. Save to a new CSV\n",
    "out_path = \"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved remapped splits to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beef5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    32922\n",
      "test      5470\n",
      "val       5460\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count each split\n",
    "counts = df['split'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0de21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pkyr</th>\n",
       "      <th>cigsmok</th>\n",
       "      <th>diagcopd</th>\n",
       "      <th>famfather</th>\n",
       "      <th>scr_res0</th>\n",
       "      <th>scr_res1</th>\n",
       "      <th>scr_res2</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>time_years</th>\n",
       "      <th>1-year-cancer</th>\n",
       "      <th>2-year-cancer</th>\n",
       "      <th>3-year-cancer</th>\n",
       "      <th>4-year-cancer</th>\n",
       "      <th>5-year-cancer</th>\n",
       "      <th>6-year-cancer</th>\n",
       "      <th>split</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111632_T0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>51.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>3.351129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110025_T0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1.566051</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120677_T0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>935.0</td>\n",
       "      <td>2.559890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121403_T0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>54.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>5.478439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>val</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129141_T0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>5.431896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43847</th>\n",
       "      <td>200508_T2</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>114.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>4.882957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43848</th>\n",
       "      <td>204854_T2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.444216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43849</th>\n",
       "      <td>205247_T2</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>32.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.460643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43850</th>\n",
       "      <td>211365_T2</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>40.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>5.422313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>val</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43851</th>\n",
       "      <td>214542_T2</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>57.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>5.444216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>train</td>\n",
       "      <td>/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43852 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pid  gender  age    pkyr  cigsmok  diagcopd  famfather  scr_res0  \\\n",
       "0      111632_T0       1   56   51.25        1       0.0        0.0         3   \n",
       "1      110025_T0       1   71   90.00        0       0.0        0.0         2   \n",
       "2      120677_T0       1   58   80.00        1       0.0        1.0         2   \n",
       "3      121403_T0       1   56   54.00        1       0.0        0.0         2   \n",
       "4      129141_T0       1   55   80.00        1       0.0        0.0         4   \n",
       "...          ...     ...  ...     ...      ...       ...        ...       ...   \n",
       "43847  200508_T2       1   67  114.00        1       0.0        NaN         4   \n",
       "43848  204854_T2       2   61   54.00        0       0.0        0.0         4   \n",
       "43849  205247_T2       2   61   32.25        1       0.0        0.0         4   \n",
       "43850  211365_T2       2   59   40.00        1       0.0        0.0         1   \n",
       "43851  214542_T2       1   63   57.75        0       0.0        1.0         2   \n",
       "\n",
       "       scr_res1  scr_res2  ...    time  time_years  1-year-cancer  \\\n",
       "0             2         2  ...  1224.0    3.351129              0   \n",
       "1             2         5  ...   572.0    1.566051              0   \n",
       "2             3         2  ...   935.0    2.559890              0   \n",
       "3             1         3  ...  2001.0    5.478439              0   \n",
       "4             6         5  ...  1984.0    5.431896              0   \n",
       "...         ...       ...  ...     ...         ...            ...   \n",
       "43847         6         6  ...  1784.0    4.882957              0   \n",
       "43848         4         5  ...  1989.0    5.444216              0   \n",
       "43849         4         5  ...  1995.0    5.460643              0   \n",
       "43850         3         2  ...  1981.0    5.422313              0   \n",
       "43851         4         2  ...  1989.0    5.444216              0   \n",
       "\n",
       "       2-year-cancer  3-year-cancer  4-year-cancer  5-year-cancer  \\\n",
       "0                  0              0             -1             -1   \n",
       "1                 -1             -1             -1             -1   \n",
       "2                  0             -1             -1             -1   \n",
       "3                  0              0              0              0   \n",
       "4                  0              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "43847              0              0              0             -1   \n",
       "43848              0              0              0              0   \n",
       "43849              0              0              0              0   \n",
       "43850              0              0              0              0   \n",
       "43851              0              0              0              0   \n",
       "\n",
       "       6-year-cancer  split                                          file_path  \n",
       "0                 -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "1                 -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "2                 -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "3                 -1    val  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "4                 -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "...              ...    ...                                                ...  \n",
       "43847             -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "43848             -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "43849             -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "43850             -1    val  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "43851             -1  train  /rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Mo...  \n",
       "\n",
       "[43852 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da920cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Optional, Callable\n",
    "class VolumeProcessor:\n",
    "    def __init__(self, chunk_depth=3, out_size=(448, 448), vmin=-1000, vmax=150, eps=0.00005):\n",
    "        self.chunk_depth = chunk_depth\n",
    "        self.out_size = out_size\n",
    "        self.vmin = vmin\n",
    "        self.vmax = vmax\n",
    "        self.eps = eps\n",
    "    \n",
    "    def _preprocess_volume(self, nifti_path):\n",
    "        # Load NIfTI file\n",
    "        nifti = nib.load(nifti_path)\n",
    "        volume = nifti.get_fdata()\n",
    "        \n",
    "        # Normalize to 0-1 range\n",
    "        volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)\n",
    "        \n",
    "        return volume\n",
    "    \n",
    "    def _get_chunks(self, volume):\n",
    "        # Extract 3-slice chunks with stride 1\n",
    "        depth, height, width = volume.shape\n",
    "        \n",
    "        # Create list of chunks\n",
    "        chunks = []\n",
    "        for i in range(0, depth - self.chunk_depth + 1):\n",
    "            chunk = volume[i:i+self.chunk_depth]  # Get 3 consecutive slices\n",
    "            \n",
    "            # Resize if needed\n",
    "            if (height, width) != self.out_size:\n",
    "                chunk_resized = np.zeros((self.chunk_depth, *self.out_size))\n",
    "                for j in range(self.chunk_depth):\n",
    "                    # Use CV2 or other resize method here\n",
    "                    # For simplicity, this is a placeholder\n",
    "                    chunk_resized[j] = chunk[j]  # Replace with actual resize\n",
    "                chunk = chunk_resized\n",
    "            \n",
    "            # Create \"RGB\" channels by duplicating (3D to pseudo-RGB)\n",
    "            chunk_rgb = np.stack([chunk] * 3, axis=1)  # [3, 3, H, W]\n",
    "            chunks.append(chunk_rgb)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def process_file(self, nifti_path):\n",
    "        volume = self._preprocess_volume(nifti_path)\n",
    "        chunks = self._get_chunks(volume)\n",
    "        return chunks\n",
    "\n",
    "class NLSTDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,\n",
    "                 processor: VolumeProcessor,\n",
    "                 label_cols: List[str],\n",
    "                 augment: Optional[Callable[[torch.Tensor], torch.Tensor]] = None):\n",
    "        df = df[df.file_path.notna()].reset_index(drop=True)\n",
    "        self.df = df\n",
    "        self.proc = processor\n",
    "        self.labels = label_cols\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int, from_rsrch1: bool = True):\n",
    "        row = self.df.iloc[idx]  # Shape: pandas.Series (1D row data)\n",
    "        nii_path = row.file_path  # Shape: str (file path)\n",
    "        if from_rsrch1:\n",
    "            old = \"/rsrch7/home/ip_rsrch/wulab/Lung_Foundation_Model_Data_/Batchs_Nii/Vols/NLST\"\n",
    "            new = \"/rsrch1/ip/msalehjahromi/data/NLST\"\n",
    "            nii_path = nii_path.replace(old, new)\n",
    "        #print(f\"[Data] Loading volume {idx}: {nii_path}\")\n",
    "        nii = nib.load(nii_path)\n",
    "        vol = nii.get_fdata().astype(np.float32)  # Shape: [H, W, D] 3D volume\n",
    "        spacing = nii.header.get_zooms()  # Get voxel spacing (dx, dy, dz)\n",
    "        H, W, D = vol.shape\n",
    "        #print(f\"[Data] Volume shape: {vol.shape}\")\n",
    "        num_chunks = D // self.proc.chunk_depth  # Shape: scalar (number of chunks)\n",
    "\n",
    "        windows = []  # Will collect chunks\n",
    "        for i in range(num_chunks):\n",
    "            arr = vol[:, :, i*self.proc.chunk_depth:(i+1)*self.proc.chunk_depth]  # Shape: [H, W, chunk_depth]\n",
    "            arr = np.clip(arr, self.proc.vmin, self.proc.vmax)  # Shape: [H, W, chunk_depth]\n",
    "            arr = (arr - self.proc.vmin) / (self.proc.vmax - self.proc.vmin)  # Shape: [H, W, chunk_depth]\n",
    "            arr = np.clip(arr, self.proc.eps, 1.0 - self.proc.eps)  # Shape: [H, W, chunk_depth]\n",
    "\n",
    "            t = torch.from_numpy(arr).permute(2, 0, 1)  # Shape: [chunk_depth, H, W]\n",
    "            t = F.interpolate(t.unsqueeze(0), size=self.proc.out_size,\n",
    "                              mode=\"bilinear\", align_corners=False).squeeze(0)  # Shape: [chunk_depth, 448, 448]\n",
    "            t = (t - 0.5) / 0.5  # Shape: [chunk_depth, 448, 448]\n",
    "            windows.append(t)  # Add to list\n",
    "\n",
    "        if self.augment is not None:\n",
    "            windows = [self.augment(c) for c in windows]\n",
    "        chunks = torch.stack(windows, dim=0)  # Shape: [num_chunks, chunk_depth, 448, 448]\n",
    "        labels = row[self.labels].to_numpy(dtype=np.float32)  # Shape: [num_labels] (e.g., [3] for 3 time points)\n",
    "        mask = (labels != -1)  # Shape: [num_labels] boolean mask\n",
    "        return chunks, labels, mask, spacing  # Return shapes: [num_chunks, chunk_depth, 448, 448], [num_labels], [num_labels], (dx, dy, dz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b65f30a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43852, 21)\n",
      "(43852, 21)\n",
      "43852\n",
      "hello hello\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello hello\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# now each batch will on average contain roughly equal numbers of 0s and 1s\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunks, labels, mask, spacing \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# train your model…\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels, mask, spacing)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~.local/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 1. Load & filter ---\n",
    "csv_path = \"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "label_col = \"1-year-cancer\"\n",
    "print(df.shape)\n",
    "# drop any rows where this label is –1\n",
    "df = df[df[label_col] != -1].reset_index(drop=True)\n",
    "print(df.shape)\n",
    "# --- 2. Compute class counts & weights ---\n",
    "# value_counts gives e.g. {0: 10000, 1: 500}\n",
    "counts = df[label_col].value_counts().to_dict()\n",
    "# invert freq to get per-class weight:\n",
    "class_weights = {cls: 1.0/count for cls, count in counts.items()}\n",
    "\n",
    "# assign each sample its class weight\n",
    "sample_weights = df[label_col].map(class_weights).tolist()\n",
    "print(len(sample_weights))\n",
    "# create a sampler that draws N=df.shape[0] samples with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# --- 3. Plug into your DataLoader ---\n",
    "# assume you’ve defined NLSTDataset exactly as above, but you pass in the filtered df\n",
    "label_cols = ['1-year-cancer', '2-year-cancer', '3-year-cancer', '4-year-cancer', '5-year-cancer', '6-year-cancer']\n",
    "    \n",
    "processor = VolumeProcessor(chunk_depth=3, out_size=(448, 448))\n",
    "dataset = NLSTDataset(df, processor, label_cols)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    sampler=sampler,      # ← balanced sampling instead of shuffle=True\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(\"hello hello\")\n",
    "# now each batch will on average contain roughly equal numbers of 0s and 1s\n",
    "for chunks, labels, mask, spacing in loader:\n",
    "    # train your model…\n",
    "    print(labels, mask, spacing)\n",
    "    print()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a276b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.1361, 19.0005, 15.1556, 12.7369,  8.5288,  4.3790])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def calculate_class_weights(df, label_cols):\n",
    "#     \"\"\"Calculate class weights for imbalanced classification\"\"\"\n",
    "#     weights = []\n",
    "    \n",
    "#     for col in label_cols:\n",
    "#         # Count positive and negative samples\n",
    "#         pos_count = df[col].sum()\n",
    "#         neg_count = len(df) - pos_count\n",
    "        \n",
    "#         # Calculate weight (higher weight for minority class)\n",
    "#         if pos_count > 0 and neg_count > 0:\n",
    "#             weight = neg_count / pos_count  # Weight for positive class\n",
    "#         else:\n",
    "#             weight = 1.0\n",
    "        \n",
    "#         weights.append(weight)\n",
    "    \n",
    "#     return torch.tensor(weights)\n",
    "\n",
    "# import torch\n",
    "\n",
    "def calculate_class_weights(df, label_cols):\n",
    "    \"\"\"Calculate class weights for imbalanced binary labels (only 0 vs 1, ignore -1).\"\"\"\n",
    "    weights = []\n",
    "    for col in label_cols:\n",
    "        # Only keep 0/1 entries\n",
    "        vals = df[col].isin([0, 1])\n",
    "        pos_count = (df.loc[vals, col] == 1).sum()\n",
    "        neg_count = (df.loc[vals, col] == 0).sum()\n",
    "\n",
    "        # If both classes exist, weight positive by neg/pos; else fallback to 1.0\n",
    "        if pos_count > 0 and neg_count > 0:\n",
    "            w = neg_count / pos_count\n",
    "        else:\n",
    "            w = 1.0\n",
    "\n",
    "        weights.append(w)\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "\n",
    "csv_path=\"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_.csv\"\n",
    " \n",
    "df=pd.read_csv(csv_path)#.query(\"split == 'train'\")\n",
    "label_cols = ['1-year-cancer', '2-year-cancer', '3-year-cancer', '4-year-cancer', '5-year-cancer', '6-year-cancer']\n",
    "calculate_class_weights(df, label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5501dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1-year-cancer  2-year-cancer  3-year-cancer  4-year-cancer  5-year-cancer  \\\n",
      "-1              0            911           1896           3342          12969   \n",
      " 0          42236          40794          39359          37561          27642   \n",
      " 1           1616           2147           2597           2949           3241   \n",
      "\n",
      "    6-year-cancer  \n",
      "-1          25472  \n",
      " 0          14963  \n",
      " 1           3417  \n"
     ]
    }
   ],
   "source": [
    "counts = df[label_cols].apply(pd.Series.value_counts).fillna(0).astype(int)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24137474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.25,\n",
       " 19.047619047619047,\n",
       " 15.6,\n",
       " 12.758620689655173,\n",
       " 8.4375,\n",
       " 4.382352941176471)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42/1.6, 40/2.1, 39/2.5, 37/2.9, 27/3.2, 14.9/3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8a7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
