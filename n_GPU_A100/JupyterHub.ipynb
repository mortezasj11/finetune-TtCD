{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2aed02-3d9c-4f45-b9fd-92d71e1238b6",
   "metadata": {},
   "source": [
    "# 1. DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baeaf912-771e-48be-8d7e-56dbdd7b5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integration syncronization impliment integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96334761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mc7e2ca438b78            \u001b[m  Wed May 14 05:37:36 2025  \u001b[1m\u001b[30m535.216.01\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA A100-SXM4-40GB\u001b[m |\u001b[31m 33'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  624\u001b[m / \u001b[33m40960\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA A100-SXM4-40GB\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  624\u001b[m / \u001b[33m40960\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA A100-SXM4-40GB\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  624\u001b[m / \u001b[33m40960\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA A100-SXM4-40GB\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 5699\u001b[m / \u001b[33m40960\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall histolab -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc22ab11-89d3-4805-9cff-b2ee1542fb68",
   "metadata": {},
   "source": [
    "docker run -it --rm --gpus '\"device=4,5,6,7\"' -p 12344:12344 --name msalehjahromi --shm-size=192G  --user $(id -u):$(id -g) --group-add 1944259512 --cpuset-cpus=49-96 -v /rsrch7/home/ip_rsrch/wulab/:/rsrch7/home/ip_rsrch/wulab -v /rsrch1/ip/msalehjahromi/:/rsrch1/ip/msalehjahromi --name mori_jupyter nnunetv2:msalehjahromi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f2e39-b110-4be8-82bd-5443f49ca638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pip', 'install', '-q', '--extra-index-url', 'https://download.pytorch.org/whl/cu117', 'torch==2.0.0', 'torchvision==0.15.0', 'omegaconf', 'torchmetrics==0.10.3', 'fvcore', 'iopath', 'xformers==0.0.18', 'submitit', 'numpy<2.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tabulate is installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py is installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "histolab 0.6.0 requires numpy<1.23.1,>=1.18.4, but you have numpy 1.26.4 which is incompatible.\n",
      "histolab 0.6.0 requires scipy<1.8.2,>=1.5.0, but you have scipy 1.15.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pip', 'install', '-q', '--extra-index-url', 'https://pypi.nvidia.com', 'cuml-cu11']\n",
      "['pip', 'install', '-q', 'black==22.6.0', 'flake8==5.0.4', 'pylint==2.15.0']\n",
      "['pip', 'install', '-q', 'mmsegmentation==0.27.0']\n",
      "['pip', 'install', '-q', 'mmcv-full==1.5.0']\n"
     ]
    }
   ],
   "source": [
    "# Install required packages first\n",
    "import os\n",
    "import subprocess\n",
    "pip_commands = [\n",
    "    [\"pip\", \"install\",\"-q\", \"--extra-index-url\", \"https://download.pytorch.org/whl/cu117\", \n",
    "     \"torch==2.0.0\", \"torchvision==0.15.0\", \"omegaconf\", \"torchmetrics==0.10.3\", \n",
    "     \"fvcore\", \"iopath\", \"xformers==0.0.18\", \"submitit\", \"numpy<2.0\"],\n",
    "    [\"pip\", \"install\", \"-q\",  \"--extra-index-url\", \"https://pypi.nvidia.com\", \"cuml-cu11\"],\n",
    "    [\"pip\", \"install\",\"-q\",  \"black==22.6.0\", \"flake8==5.0.4\", \"pylint==2.15.0\"],\n",
    "    [\"pip\", \"install\", \"-q\", \"mmsegmentation==0.27.0\"],\n",
    "    [\"pip\", \"install\",\"-q\", \"mmcv-full==1.5.0\"],\n",
    "    [\"pip\", \"install\",\"-q\", \"nibabel\"]\n",
    "]\n",
    "\n",
    "for cmd in pip_commands:\n",
    "    try:\n",
    "        print(cmd)\n",
    "        subprocess.run(cmd, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install packages with command: {cmd}\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcbc99-2187-44d4-ba49-db2ff8a4ed85",
   "metadata": {},
   "source": [
    "### The following (x_ddp.py not x_ddp_full.py) got stuck after\n",
    "\n",
    "2025-05-05 22:04:16,876 - INFO - Step 100 | Loss: 3.616974\n",
    "\n",
    "2025-05-05 22:05:19,696 - INFO - Step 200 | Loss: 0.003891\n",
    "\n",
    "2025-05-05 22:06:32,967 - INFO - Step 300 | Loss: 0.032542\n",
    "\n",
    "2025-05-05 22:08:02,341 - INFO - Step 400 | Loss: 0.011597\n",
    "\n",
    "### and also did not save the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05767f94-9f7b-48ca-ba19-0d76d8e0b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']\n",
      "Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']\n",
      "Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 05:46:34,103 - INFO - Starting training on 3 GPUs with full model copies (DDP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Dataset Statistics ====\n",
      "Total samples: 43852\n",
      "Training samples: 32922\n",
      "Validation samples: 5460\n",
      "\n",
      "1-year-cancer:\n",
      "  Train positive: 1242 (3.77%)\n",
      "  Val positive: 186 (3.41%)\n",
      "\n",
      "2-year-cancer:\n",
      "  Train positive: 1638 (4.98%)\n",
      "  Val positive: 253 (4.63%)\n",
      "\n",
      "3-year-cancer:\n",
      "  Train positive: 1970 (5.98%)\n",
      "  Val positive: 312 (5.71%)\n",
      "\n",
      "4-year-cancer:\n",
      "  Train positive: 2226 (6.76%)\n",
      "  Val positive: 360 (6.59%)\n",
      "\n",
      "5-year-cancer:\n",
      "  Train positive: 2436 (7.40%)\n",
      "  Val positive: 402 (7.36%)\n",
      "\n",
      "6-year-cancer:\n",
      "  Train positive: 2562 (7.78%)\n",
      "  Val positive: 426 (7.80%)\n",
      "============================\n",
      "\n",
      "Total validation samples: 5460\n",
      "Created distributed validation loader, each rank processes ~1718 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 05:46:41,393 - INFO - using MLP layer as FFN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cls_token in weights with shape: torch.Size([1, 1, 768])\n",
      "Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768\n",
      "Found cls_token in weights with shape: torch.Size([1, 1, 768])\n",
      "Found cls_token in weights with shape: torch.Size([1, 1, 768])\n",
      "Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:893: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  f\"storage size: {model_ct.cls_token.storage().size()}\")\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:884: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:893: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  f\"storage size: {model_ct.cls_token.storage().size()}\")\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:884: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:893: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  f\"storage size: {model_ct.cls_token.storage().size()}\")\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:884: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768\n",
      "Verifying all parameters are on cuda:0\n",
      "All parameters successfully verified on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 05:46:44,246 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)\n",
      "2025-05-14 05:46:44,246 - INFO - Aggregator parameters: 26 (LR: 0.0001)\n",
      "2025-05-14 05:46:44,247 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues\n",
      "2025-05-14 05:46:44,251 - INFO - using MLP layer as FFN\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if hasattr(m, n) and getattr(m, n).storage().size() == 0:\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if hasattr(m, n) and getattr(m, n).storage().size() == 0:\n",
      "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if hasattr(m, n) and getattr(m, n).storage().size() == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250514_054647.jsonl\n",
      "Will save checkpoints to ./output_ddp/checkpoints\n",
      "\n",
      "Training Configuration:\n",
      "Max chunks per sample: 72\n",
      "Learning rate: 0.0001\n",
      "Number of tasks: 6\n",
      "Validation frequency: 50000 steps\n",
      "Number of epochs: 10\n",
      "Warmup steps: 1000\n",
      "World size: 3\n",
      "Device: cuda\n",
      "\n",
      "Epoch 1: All parameters already unfrozen (strategy: all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage_data_ptr = tensors[0].storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if x.storage().data_ptr() != storage_data_ptr:\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage_data_ptr = tensors[0].storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if x.storage().data_ptr() != storage_data_ptr:\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage_data_ptr = tensors[0].storage().data_ptr()\n",
      "/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if x.storage().data_ptr() != storage_data_ptr:\n",
      "/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2000 (Epoch 1):\n",
      "Loss: 0.5353\n",
      "Learning rate: 0.000100\n",
      "Accuracy: Task 0: 0.02 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.05 | Task 4: 0.08 | Task 5: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 06:37:44,828 - INFO - iteration: 2000 | epoch: 0 | loss: 0.5353 | lr: 0.0001 | type: training | acc_task0: 0.0200 | acc_task1: 0.9693 | acc_task2: 0.9585 | acc_task3: 0.0539 | acc_task4: 0.0767 | acc_task5: 0.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4000 (Epoch 1):\n",
      "Loss: 0.0147\n",
      "Learning rate: 0.000100\n",
      "Accuracy: Task 0: 0.50 | Task 1: 0.97 | Task 2: 0.97 | Task 3: 0.46 | Task 4: 0.39 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 07:32:24,440 - INFO - iteration: 4000 | epoch: 0 | loss: 0.0147 | lr: 0.0001 | type: training | acc_task0: 0.5025 | acc_task1: 0.9741 | acc_task2: 0.9652 | acc_task3: 0.4597 | acc_task4: 0.3881 | acc_task5: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6000 (Epoch 1):\n",
      "Loss: 0.0149\n",
      "Learning rate: 0.000099\n",
      "Accuracy: Task 0: 0.66 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.62 | Task 4: 0.57 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 08:23:53,927 - INFO - iteration: 6000 | epoch: 0 | loss: 0.0149 | lr: 0.0001 | type: training | acc_task0: 0.6630 | acc_task1: 0.9730 | acc_task2: 0.9640 | acc_task3: 0.6223 | acc_task4: 0.5669 | acc_task5: 0.8745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8000 (Epoch 1):\n",
      "Loss: 0.0159\n",
      "Learning rate: 0.000099\n",
      "Accuracy: Task 0: 0.74 | Task 1: 0.97 | Task 2: 0.97 | Task 3: 0.71 | Task 4: 0.66 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 09:36:57,671 - INFO - iteration: 8000 | epoch: 0 | loss: 0.0159 | lr: 0.0001 | type: training | acc_task0: 0.7446 | acc_task1: 0.9739 | acc_task2: 0.9650 | acc_task3: 0.7070 | acc_task4: 0.6594 | acc_task5: 0.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10000 (Epoch 1):\n",
      "Loss: 0.0139\n",
      "Learning rate: 0.000098\n",
      "Accuracy: Task 0: 0.79 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.76 | Task 4: 0.71 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 10:41:10,922 - INFO - iteration: 10000 | epoch: 0 | loss: 0.0139 | lr: 0.0001 | type: training | acc_task0: 0.7917 | acc_task1: 0.9731 | acc_task2: 0.9643 | acc_task3: 0.7563 | acc_task4: 0.7131 | acc_task5: 0.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model components to:\n",
      "  Base: base_model_epoch_1.pt\n",
      "  Aggregator: aggregator_epoch_1.pt\n",
      "Saved checkpoint at epoch 1 to ./output_ddp/checkpoints/model_epoch_1.pt\n",
      "\n",
      "Saved checkpoint for epoch 1\n",
      "\n",
      "Step 12000 (Epoch 2):\n",
      "Loss: 0.0260\n",
      "Learning rate: 0.000097\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.92 | Task 5: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 11:57:00,101 - INFO - iteration: 12000 | epoch: 1 | loss: 0.0260 | lr: 0.0001 | type: training | acc_task0: 0.9826 | acc_task1: 0.9706 | acc_task2: 0.9581 | acc_task3: 0.9481 | acc_task4: 0.9243 | acc_task5: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 14000 (Epoch 2):\n",
      "Loss: 0.0530\n",
      "Learning rate: 0.000096\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 13:27:30,722 - INFO - iteration: 14000 | epoch: 1 | loss: 0.0530 | lr: 0.0001 | type: training | acc_task0: 0.9839 | acc_task1: 0.9735 | acc_task2: 0.9635 | acc_task3: 0.9548 | acc_task4: 0.9333 | acc_task5: 0.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 16000 (Epoch 2):\n",
      "Loss: 0.0212\n",
      "Learning rate: 0.000095\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.94 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 14:39:00,560 - INFO - iteration: 16000 | epoch: 1 | loss: 0.0212 | lr: 0.0001 | type: training | acc_task0: 0.9853 | acc_task1: 0.9744 | acc_task2: 0.9644 | acc_task3: 0.9565 | acc_task4: 0.9365 | acc_task5: 0.8786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 20000 (Epoch 2):\n",
      "Loss: 0.0461\n",
      "Learning rate: 0.000092\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 16:27:47,625 - INFO - iteration: 20000 | epoch: 1 | loss: 0.0461 | lr: 0.0001 | type: training | acc_task0: 0.9853 | acc_task1: 0.9747 | acc_task2: 0.9637 | acc_task3: 0.9546 | acc_task4: 0.9333 | acc_task5: 0.8756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model components to:\n",
      "  Base: base_model_epoch_2.pt\n",
      "  Aggregator: aggregator_epoch_2.pt\n",
      "Saved checkpoint at epoch 2 to ./output_ddp/checkpoints/model_epoch_2.pt\n",
      "\n",
      "Saved checkpoint for epoch 2\n",
      "\n",
      "Step 22000 (Epoch 3):\n",
      "Loss: 0.0531\n",
      "Learning rate: 0.000090\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.97 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 17:36:37,315 - INFO - iteration: 22000 | epoch: 2 | loss: 0.0531 | lr: 0.0001 | type: training | acc_task0: 0.9819 | acc_task1: 0.9730 | acc_task2: 0.9661 | acc_task3: 0.9562 | acc_task4: 0.9343 | acc_task5: 0.8813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 24000 (Epoch 3):\n",
      "Loss: 0.0492\n",
      "Learning rate: 0.000088\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 18:29:49,311 - INFO - iteration: 24000 | epoch: 2 | loss: 0.0492 | lr: 0.0001 | type: training | acc_task0: 0.9838 | acc_task1: 0.9733 | acc_task2: 0.9639 | acc_task3: 0.9539 | acc_task4: 0.9306 | acc_task5: 0.8719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 26000 (Epoch 3):\n",
      "Loss: 0.0234\n",
      "Learning rate: 0.000086\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 19:31:58,803 - INFO - iteration: 26000 | epoch: 2 | loss: 0.0234 | lr: 0.0001 | type: training | acc_task0: 0.9844 | acc_task1: 0.9740 | acc_task2: 0.9646 | acc_task3: 0.9565 | acc_task4: 0.9343 | acc_task5: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 28000 (Epoch 3):\n",
      "Loss: 0.0162\n",
      "Learning rate: 0.000084\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 20:24:00,716 - INFO - iteration: 28000 | epoch: 2 | loss: 0.0162 | lr: 0.0001 | type: training | acc_task0: 0.9840 | acc_task1: 0.9733 | acc_task2: 0.9647 | acc_task3: 0.9561 | acc_task4: 0.9343 | acc_task5: 0.8790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 30000 (Epoch 3):\n",
      "Loss: 0.3656\n",
      "Learning rate: 0.000081\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.97 | Task 3: 0.96 | Task 4: 0.94 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 21:13:29,293 - INFO - iteration: 30000 | epoch: 2 | loss: 0.3656 | lr: 0.0001 | type: training | acc_task0: 0.9842 | acc_task1: 0.9740 | acc_task2: 0.9651 | acc_task3: 0.9570 | acc_task4: 0.9356 | acc_task5: 0.8805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model components to:\n",
      "  Base: base_model_epoch_3.pt\n",
      "  Aggregator: aggregator_epoch_3.pt\n",
      "Saved checkpoint at epoch 3 to ./output_ddp/checkpoints/model_epoch_3.pt\n",
      "\n",
      "Saved checkpoint for epoch 3\n",
      "\n",
      "Step 32000 (Epoch 4):\n",
      "Loss: 0.0506\n",
      "Learning rate: 0.000079\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:12:43,444 - INFO - iteration: 32000 | epoch: 3 | loss: 0.0506 | lr: 0.0001 | type: training | acc_task0: 0.9838 | acc_task1: 0.9731 | acc_task2: 0.9617 | acc_task3: 0.9516 | acc_task4: 0.9289 | acc_task5: 0.8672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 34000 (Epoch 4):\n",
      "Loss: 0.0564\n",
      "Learning rate: 0.000076\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 23:27:01,326 - INFO - iteration: 34000 | epoch: 3 | loss: 0.0564 | lr: 0.0001 | type: training | acc_task0: 0.9829 | acc_task1: 0.9718 | acc_task2: 0.9615 | acc_task3: 0.9528 | acc_task4: 0.9285 | acc_task5: 0.8693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 36000 (Epoch 4):\n",
      "Loss: 0.0424\n",
      "Learning rate: 0.000074\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 00:28:43,653 - INFO - iteration: 36000 | epoch: 3 | loss: 0.0424 | lr: 0.0001 | type: training | acc_task0: 0.9840 | acc_task1: 0.9743 | acc_task2: 0.9643 | acc_task3: 0.9543 | acc_task4: 0.9319 | acc_task5: 0.8760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 38000 (Epoch 4):\n",
      "Loss: 0.0514\n",
      "Learning rate: 0.000071\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 01:33:31,180 - INFO - iteration: 38000 | epoch: 3 | loss: 0.0514 | lr: 0.0001 | type: training | acc_task0: 0.9843 | acc_task1: 0.9740 | acc_task2: 0.9636 | acc_task3: 0.9541 | acc_task4: 0.9323 | acc_task5: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 40000 (Epoch 4):\n",
      "Loss: 0.0257\n",
      "Learning rate: 0.000068\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 02:42:21,249 - INFO - iteration: 40000 | epoch: 3 | loss: 0.0257 | lr: 0.0001 | type: training | acc_task0: 0.9842 | acc_task1: 0.9740 | acc_task2: 0.9640 | acc_task3: 0.9553 | acc_task4: 0.9330 | acc_task5: 0.8786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model components to:\n",
      "  Base: base_model_epoch_4.pt\n",
      "  Aggregator: aggregator_epoch_4.pt\n",
      "Saved checkpoint at epoch 4 to ./output_ddp/checkpoints/model_epoch_4.pt\n",
      "\n",
      "Saved checkpoint for epoch 4\n",
      "\n",
      "Step 42000 (Epoch 5):\n",
      "Loss: 0.0220\n",
      "Learning rate: 0.000065\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.97 | Task 2: 0.97 | Task 3: 0.96 | Task 4: 0.94 | Task 5: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 03:45:30,195 - INFO - iteration: 42000 | epoch: 4 | loss: 0.0220 | lr: 0.0001 | type: training | acc_task0: 0.9892 | acc_task1: 0.9748 | acc_task2: 0.9696 | acc_task3: 0.9619 | acc_task4: 0.9404 | acc_task5: 0.8943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 44000 (Epoch 5):\n",
      "Loss: 0.0716\n",
      "Learning rate: 0.000062\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.98 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 04:54:30,866 - INFO - iteration: 44000 | epoch: 4 | loss: 0.0716 | lr: 0.0001 | type: training | acc_task0: 0.9860 | acc_task1: 0.9785 | acc_task2: 0.9631 | acc_task3: 0.9557 | acc_task4: 0.9310 | acc_task5: 0.8712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 46000 (Epoch 5):\n",
      "Loss: 0.0235\n",
      "Learning rate: 0.000059\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.98 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 05:50:19,908 - INFO - iteration: 46000 | epoch: 4 | loss: 0.0235 | lr: 0.0001 | type: training | acc_task0: 0.9858 | acc_task1: 0.9765 | acc_task2: 0.9636 | acc_task3: 0.9548 | acc_task4: 0.9315 | acc_task5: 0.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 48000 (Epoch 5):\n",
      "Loss: 0.0249\n",
      "Learning rate: 0.000056\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.98 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 06:43:16,888 - INFO - iteration: 48000 | epoch: 4 | loss: 0.0249 | lr: 0.0001 | type: training | acc_task0: 0.9860 | acc_task1: 0.9764 | acc_task2: 0.9644 | acc_task3: 0.9558 | acc_task4: 0.9335 | acc_task5: 0.8739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached validation point at step 50000 (in epoch 5)\n",
      "\n",
      "=== Starting distributed validation at step 50000 ===\n",
      "\n",
      "Step 52000 (Epoch 6):\n",
      "Loss: 0.0597\n",
      "Learning rate: 0.000050\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.96 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:01:43,243 - INFO - iteration: 52000 | epoch: 5 | loss: 0.0597 | lr: 0.0001 | type: training | acc_task0: 0.9806 | acc_task1: 0.9702 | acc_task2: 0.9631 | acc_task3: 0.9615 | acc_task4: 0.9327 | acc_task5: 0.8722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 54000 (Epoch 6):\n",
      "Loss: 0.0263\n",
      "Learning rate: 0.000047\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:59:37,483 - INFO - iteration: 54000 | epoch: 5 | loss: 0.0263 | lr: 0.0000 | type: training | acc_task0: 0.9818 | acc_task1: 0.9685 | acc_task2: 0.9565 | acc_task3: 0.9492 | acc_task4: 0.9272 | acc_task5: 0.8645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 56000 (Epoch 6):\n",
      "Loss: 0.0351\n",
      "Learning rate: 0.000044\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 10:59:56,689 - INFO - iteration: 56000 | epoch: 5 | loss: 0.0351 | lr: 0.0000 | type: training | acc_task0: 0.9838 | acc_task1: 0.9710 | acc_task2: 0.9592 | acc_task3: 0.9526 | acc_task4: 0.9303 | acc_task5: 0.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 58000 (Epoch 6):\n",
      "Loss: 0.0368\n",
      "Learning rate: 0.000041\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 12:02:17,880 - INFO - iteration: 58000 | epoch: 5 | loss: 0.0368 | lr: 0.0000 | type: training | acc_task0: 0.9842 | acc_task1: 0.9721 | acc_task2: 0.9604 | acc_task3: 0.9524 | acc_task4: 0.9296 | acc_task5: 0.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 60000 (Epoch 6):\n",
      "Loss: 1.9016\n",
      "Learning rate: 0.000038\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 13:01:01,155 - INFO - iteration: 60000 | epoch: 5 | loss: 1.9016 | lr: 0.0000 | type: training | acc_task0: 0.9844 | acc_task1: 0.9731 | acc_task2: 0.9612 | acc_task3: 0.9534 | acc_task4: 0.9302 | acc_task5: 0.8717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 62000 (Epoch 6):\n",
      "Loss: 0.0520\n",
      "Learning rate: 0.000035\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 13:54:32,935 - INFO - iteration: 62000 | epoch: 5 | loss: 0.0520 | lr: 0.0000 | type: training | acc_task0: 0.9846 | acc_task1: 0.9736 | acc_task2: 0.9622 | acc_task3: 0.9546 | acc_task4: 0.9318 | acc_task5: 0.8747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model components to:\n",
      "  Base: base_model_epoch_6.pt\n",
      "  Aggregator: aggregator_epoch_6.pt\n",
      "Saved checkpoint at epoch 6 to ./output_ddp/checkpoints/model_epoch_6.pt\n",
      "\n",
      "Saved checkpoint for epoch 6\n",
      "\n",
      "Step 64000 (Epoch 7):\n",
      "Loss: 0.0352\n",
      "Learning rate: 0.000032\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 14:51:44,664 - INFO - iteration: 64000 | epoch: 6 | loss: 0.0352 | lr: 0.0000 | type: training | acc_task0: 0.9873 | acc_task1: 0.9716 | acc_task2: 0.9599 | acc_task3: 0.9538 | acc_task4: 0.9258 | acc_task5: 0.8642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 66000 (Epoch 7):\n",
      "Loss: 0.0437\n",
      "Learning rate: 0.000029\n",
      "Accuracy: Task 0: 0.99 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 15:48:54,630 - INFO - iteration: 66000 | epoch: 6 | loss: 0.0437 | lr: 0.0000 | type: training | acc_task0: 0.9856 | acc_task1: 0.9721 | acc_task2: 0.9593 | acc_task3: 0.9523 | acc_task4: 0.9260 | acc_task5: 0.8616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 68000 (Epoch 7):\n",
      "Loss: 0.0326\n",
      "Learning rate: 0.000027\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:45:44,280 - INFO - iteration: 68000 | epoch: 6 | loss: 0.0326 | lr: 0.0000 | type: training | acc_task0: 0.9846 | acc_task1: 0.9717 | acc_task2: 0.9604 | acc_task3: 0.9527 | acc_task4: 0.9284 | acc_task5: 0.8677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 70000 (Epoch 7):\n",
      "Loss: 0.0323\n",
      "Learning rate: 0.000024\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 17:44:02,727 - INFO - iteration: 70000 | epoch: 6 | loss: 0.0323 | lr: 0.0000 | type: training | acc_task0: 0.9838 | acc_task1: 0.9715 | acc_task2: 0.9605 | acc_task3: 0.9530 | acc_task4: 0.9281 | acc_task5: 0.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 72000 (Epoch 7):\n",
      "Loss: 0.0475\n",
      "Learning rate: 0.000021\n",
      "Accuracy: Task 0: 0.98 | Task 1: 0.97 | Task 2: 0.96 | Task 3: 0.95 | Task 4: 0.93 | Task 5: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 18:43:12,959 - INFO - iteration: 72000 | epoch: 6 | loss: 0.0475 | lr: 0.0000 | type: training | acc_task0: 0.9849 | acc_task1: 0.9728 | acc_task2: 0.9615 | acc_task3: 0.9536 | acc_task4: 0.9298 | acc_task5: 0.8695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model components to:\n",
      "  Base: base_model_epoch_7.pt\n",
      "  Aggregator: aggregator_epoch_7.pt\n",
      "Saved checkpoint at epoch 7 to ./output_ddp/checkpoints/model_epoch_7.pt\n",
      "\n",
      "Saved checkpoint for epoch 7\n"
     ]
    }
   ],
   "source": [
    "# Install required packages first\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "# Set required environment variables\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"3\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_WORLD_SIZE\"] = \"3\"\n",
    "\n",
    "# Build the command with --install-packages flag removed\n",
    "command = [\n",
    "    \"python3\",\n",
    "    \"/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_launcher.py\",\n",
    "    \"--num-gpus\", \"3\",\n",
    "    \"--csv\", \"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv\",\n",
    "    \"--accum-steps\", \"400\", #200\n",
    "    \"--num-workers\", \"5\",\n",
    "    \"--epochs\", \"10\",\n",
    "    \"--lr\", \"0.0001\",\n",
    "    \"--weight-decay\", \"0.0001\",\n",
    "    \"--optimizer\", \"adamw\",\n",
    "    \"--num-attn-heads\", \"3\",\n",
    "    \"--num-layers\", \"2\",\n",
    "    \"--dropout\", \"0.3\",\n",
    "    \"--unfreeze-strategy\", \"all\",  ##\n",
    "    \"--output\", \"./output_ddp\",\n",
    "    \"--print-every\", \"2000\", #2000\n",
    "    \"--val-every\", \"50000\", #50k\n",
    "    \"--metrics-dir\", \"/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu\"\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "try:\n",
    "    subprocess.run(command, check=True)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(f\"Command output: {e.output if hasattr(e, 'output') else 'No output available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f09fe-7240-4938-805d-dc5e1434916a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd92e8e-7b09-4b03-8315-0c9a79954215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816d95a-5e31-46ae-b11b-ab7fc9daa2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
