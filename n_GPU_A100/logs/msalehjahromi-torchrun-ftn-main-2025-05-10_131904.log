 WARNING:torch.distributed.run:
 *****************************************
 Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 *****************************************
 Running command: torchrun --nproc_per_node=8 --master_port=40165 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=35097 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=53905 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=33765 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=39215 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=52475 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=40561 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 Running command: torchrun --nproc_per_node=8 --master_port=39995 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py --csv /rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv --accum-steps 20 --num-workers 10 --epochs 50 --lr 0.0001 --weight-decay 0.0001 --optimizer adamw --num-attn-heads 3 --num-layers 2 --dropout 0.3 --unfreeze-strategy all --output /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu --print-every 50 --val-every 100 --metrics-dir /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
   warnings.warn("xFormers is available (SwiGLU)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
   warnings.warn("xFormers is available (Attention)")
 /rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
   warnings.warn("xFormers is available (Block)")
 Files in the directory: ['._.DS_Store', '1_GPU_H100', 'n_GPU_A100', 'metrics_single_gpu', 'n_H100onH100', '.DS_Store', '1_GPU_A100', 'ReadMe.md', '.gitignore', 'metrics_multi_gpu', '.git']
 2025-05-10 18:20:40,109 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:41,123 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:41,209 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:41,214 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:41,214 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:42,764 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:42,764 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 2025-05-10 18:20:42,764 - INFO - Starting training on 8 GPUs with full model copies (DDP)
 msalehjahromi-torchrun-ftn-n62br:139:139 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:139:139 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:139:139 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:140:140 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:140:140 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:140:140 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:142:142 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:142:142 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:142:142 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:141:141 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:141:141 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:141:141 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:119:119 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:119:119 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:119:119 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:123:123 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:122:122 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:120:120 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:128:128 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:127:127 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:126:126 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:126:126 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:128:128 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:126:126 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:122:122 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:123:123 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:128:128 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:127:127 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:123:123 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:122:122 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:127:127 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:120:120 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:120:120 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:162:162 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:162:162 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:162:162 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:145:145 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:165:165 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:173:173 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:145:145 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:145:145 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:146:146 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:165:165 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:165:165 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:146:146 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:146:146 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:173:173 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:173:173 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:175:175 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:149:149 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:149:149 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:149:149 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:157:157 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:153:153 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:151:151 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:152:152 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:121:121 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:157:157 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:157:157 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:155:155 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:152:152 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:152:152 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:175:175 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:153:153 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:175:175 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:153:153 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:151:151 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:121:121 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:151:151 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:121:121 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:176:176 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:155:155 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:155:155 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:176:176 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:176:176 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:129:129 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:129:129 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:129:129 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:131:131 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:130:130 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:133:133 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:136:136 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:131:131 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:131:131 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:133:133 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:130:130 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:136:136 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:130:130 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:133:133 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:136:136 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:171:171 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:135:135 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:171:171 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:171:171 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:135:135 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:109:109 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:135:135 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:109:109 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:109:109 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:169:169 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:113:113 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:134:134 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:167:167 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:169:169 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:169:169 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:134:134 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:113:113 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:134:134 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:167:167 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:113:113 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:167:167 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:99:99 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:99:99 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:99:99 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:100:100 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:103:103 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:105:105 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:102:102 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:105:105 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:105:105 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:102:102 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:100:100 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:100:100 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:102:102 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:103:103 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:103:103 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:161:161 [0] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:161:161 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:161:161 [0] NCCL INFO cudaDriverVersion 12040
 NCCL version 2.14.3+cuda11.7
 msalehjahromi-torchrun-ftn-n62br:172:172 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:106:106 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:101:101 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:172:172 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:172:172 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:143:143 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:106:106 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:106:106 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:101:101 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:101:101 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:143:143 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:143:143 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:104:104 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:104:104 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:104:104 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:150:150 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:144:144 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:150:150 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:150:150 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:144:144 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:144:144 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:154:154 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:111:111 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:116:116 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:166:166 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:114:114 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:154:154 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:154:154 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:116:116 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:116:116 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:163:163 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:111:111 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:111:111 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:166:166 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:166:166 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:114:114 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:114:114 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:163:163 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:163:163 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:132:132 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:170:170 [5] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:115:115 [6] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:132:132 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:132:132 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:164:164 [2] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:170:170 [5] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:164:164 [2] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:164:164 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:170:170 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:115:115 [6] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:115:115 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:110:110 [1] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:110:110 [1] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:110:110 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:168:168 [4] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:168:168 [4] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:168:168 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:112:112 [3] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:174:174 [7] NCCL INFO cudaDriverVersion 12040
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:174:174 [7] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:112:112 [3] NCCL INFO Bootstrap : Using eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:174:174 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:112:112 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.111.5<0>
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Using network Socket
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Setting affinity for GPU 6 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Setting affinity for GPU 4 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000,00000000,ffff0000
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Setting affinity for GPU 7 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Setting affinity for GPU 5 to ffff0000,00000000,00000000,00000000,ffff0000,00000000,00000000,00000000
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 00/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 00/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 01/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 01/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 02/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 02/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 03/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 03/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 04/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 04/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 00/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 01/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 05/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 06/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 05/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 00/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 00/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 07/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 01/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 02/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 06/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 08/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 01/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 02/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 02/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 03/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 07/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 09/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 03/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 08/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 03/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 04/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 10/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 04/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 04/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 05/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 09/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 05/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 11/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 12/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 13/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 05/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 06/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 10/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 06/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 14/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 11/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 07/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 06/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 12/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 07/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 08/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 15/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 07/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 13/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 08/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 09/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 16/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 08/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 09/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 10/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 17/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 14/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 09/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 18/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 10/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 11/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 11/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 15/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 19/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 12/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 16/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 12/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 10/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 11/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 12/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 20/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 21/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 13/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 13/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 22/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 17/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 13/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 14/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 14/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 14/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 23/0 : 5[90000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 15/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 18/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 16/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 15/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 15/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 19/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 16/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 17/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 16/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 18/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 17/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 20/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 17/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 19/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 18/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 21/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 20/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 18/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 19/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 19/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 22/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 21/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 20/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 20/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 7[bd000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 22/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 23/0 : 4[87000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 21/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 23/0 : 1[f000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 21/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 22/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 22/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 23/0 : 2[47000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Channel 23/0 : 0[7000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 00/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 01/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 02/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Connected all rings
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 03/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 04/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 05/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 06/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 07/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 08/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 09/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 10/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 11/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 12/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 13/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 14/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 00/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 15/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 00/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 01/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:120:640 [1] NCCL INFO comm 0x5592f43db2d0 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:121:651 [2] NCCL INFO comm 0x556179955310 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:126:633 [5] NCCL INFO comm 0x55a268dc27c0 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:122:637 [3] NCCL INFO comm 0x55dbb77b6b20 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 01/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:123:638 [4] NCCL INFO comm 0x55fd32ac52d0 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:119:631 [0] NCCL INFO comm 0x564c674d3b60 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:128:635 [7] NCCL INFO comm 0x561894954930 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 16/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 02/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 02/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 17/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:127:634 [6] NCCL INFO comm 0x55e4e32ff6f0 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 03/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 18/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 04/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 00/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 03/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 19/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 05/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 04/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 06/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 20/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 01/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 00/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 01/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 05/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 21/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 02/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 07/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 02/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 06/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 08/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 03/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 09/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 07/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 00/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 00/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 04/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 10/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 08/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 05/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 01/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 11/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 09/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 02/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 06/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 22/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 01/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 12/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 10/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 03/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 03/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 13/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Channel 23/0 : 7[bd000] -> 6[b7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 02/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 07/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 11/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 14/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 03/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 04/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 15/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 05/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 2025-05-10 18:21:30,849 - INFO - using MLP layer as FFN
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 04/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 08/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 12/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 06/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 04/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 16/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 05/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 09/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 07/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:167:668 [2] NCCL INFO comm 0x556efcfdaed0 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 05/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:169:663 [3] NCCL INFO comm 0x5576fb3d6910 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:165:639 [1] NCCL INFO comm 0x55c505e492b0 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:173:643 [5] NCCL INFO comm 0x55b0fd1a0fd0 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:175:649 [6] NCCL INFO comm 0x55c0c5d830d0 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 13/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:176:652 [7] NCCL INFO comm 0x56472b7014c0 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:162:636 [0] NCCL INFO comm 0x5602d502fae0 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 17/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 06/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 10/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 06/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 14/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 08/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 07/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:171:660 [4] NCCL INFO comm 0x563c180d2520 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 18/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 15/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 07/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 08/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 11/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 09/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 19/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 09/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 08/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 16/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 12/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 10/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 09/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 10/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 17/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 20/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 11/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 13/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 11/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 10/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 18/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 14/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 21/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 
 2-year-cancer:
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 11/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 12/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 19/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 12/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 20/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 21/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 15/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 22/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 13/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 13/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 12/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 22/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 16/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Channel 23/0 : 4[87000] -> 3[4e000] via P2P/IPC/read
 Total validation samples: 5460
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 14/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 Created distributed validation loader, each rank processes ~645 samples
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 2025-05-10 18:21:31,488 - INFO - using MLP layer as FFN
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 15/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 13/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 17/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 14/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Channel 23/0 : 5[90000] -> 4[87000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 16/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 18/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 14/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 15/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 17/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 18/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 19/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 15/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 19/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 16/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 20/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 16/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 20/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 17/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 21/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 18/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 17/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 21/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 19/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 22/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 18/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 20/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Channel 23/0 : 6[b7000] -> 5[90000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 22/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 21/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Channel 23/0 : 2[47000] -> 1[f000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 19/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 22/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 20/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Channel 23/0 : 3[4e000] -> 2[47000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 21/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:141:629 [2] NCCL INFO comm 0x55d64e581f50 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:131:655 [2] NCCL INFO comm 0x56011199ef90 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:132:689 [3] NCCL INFO comm 0x56372f4a2950 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:142:628 [3] NCCL INFO comm 0x5611642753b0 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:134:664 [5] NCCL INFO comm 0x55cf9839a000 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:139:626 [0] NCCL INFO comm 0x561bcf82ac80 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:140:627 [1] NCCL INFO comm 0x558e0caa2880 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:133:656 [4] NCCL INFO comm 0x56306ae4d510 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:129:659 [0] NCCL INFO comm 0x562a23da7830 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:130:657 [1] NCCL INFO comm 0x55d45867a3f0 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:143:679 [4] NCCL INFO comm 0x55ce04887e80 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:135:661 [6] NCCL INFO comm 0x5601cc5d80a0 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:144:682 [5] NCCL INFO comm 0x561da92b8910 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:136:665 [7] NCCL INFO comm 0x560a27856500 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:146:642 [7] NCCL INFO comm 0x55fb3f897330 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:145:641 [6] NCCL INFO comm 0x5630d6767930 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 22/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Channel 23/0 : 1[f000] -> 0[7000] via P2P/IPC/read
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:152:647 [3] NCCL INFO comm 0x559c7c4dcab0 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:149:645 [0] NCCL INFO comm 0x55b5931769b0 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:157:646 [7] NCCL INFO comm 0x564f560ddb50 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:150:681 [1] NCCL INFO comm 0x55aa599f3210 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:151:648 [2] NCCL INFO comm 0x5572d94bd1b0 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:155:653 [6] NCCL INFO comm 0x55a436bba7d0 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:154:683 [5] NCCL INFO comm 0x55731c5ea2d0 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:153:650 [4] NCCL INFO comm 0x55f4098125f0 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:99:667 [0] NCCL INFO comm 0x56376dc97280 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:100:671 [1] NCCL INFO comm 0x5647a7fe0390 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:102:672 [3] NCCL INFO comm 0x558d5e70e120 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 msalehjahromi-torchrun-ftn-n62br:101:678 [2] NCCL INFO comm 0x55e66730e220 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 msalehjahromi-torchrun-ftn-n62br:105:675 [6] NCCL INFO comm 0x5650bd4031f0 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:106:676 [7] NCCL INFO comm 0x556dcb2de820 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 2025-05-10 18:21:32,498 - INFO - using MLP layer as FFN
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 msalehjahromi-torchrun-ftn-n62br:103:673 [4] NCCL INFO comm 0x55d7d1bb2020 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:104:680 [5] NCCL INFO comm 0x56527be4dd10 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 2025-05-10 18:21:32,689 - INFO - using MLP layer as FFN
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 2025-05-10 18:21:32,794 - INFO - using MLP layer as FFN
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO Connected all trees
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
 msalehjahromi-torchrun-ftn-n62br:166:688 [3] NCCL INFO comm 0x55a040560e80 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:164:691 [2] NCCL INFO comm 0x55afeabaf480 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:163:684 [1] NCCL INFO comm 0x55fa694cac30 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:172:677 [6] NCCL INFO comm 0x55ce8e324d90 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:109:670 [0] NCCL INFO comm 0x563208c2e960 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:114:687 [5] NCCL INFO comm 0x562d226a3f90 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:174:695 [7] NCCL INFO comm 0x556f8566b050 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:111:686 [2] NCCL INFO comm 0x563c0c53c760 rank 2 nranks 8 cudaDev 2 busId 47000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:161:674 [0] NCCL INFO comm 0x564f11780f40 rank 0 nranks 8 cudaDev 0 busId 7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:110:693 [1] NCCL INFO comm 0x55ce26771820 rank 1 nranks 8 cudaDev 1 busId f000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:112:696 [3] NCCL INFO comm 0x562cfb665130 rank 3 nranks 8 cudaDev 3 busId 4e000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:115:690 [6] NCCL INFO comm 0x55c2665b5a10 rank 6 nranks 8 cudaDev 6 busId b7000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:116:685 [7] NCCL INFO comm 0x56528c40f2a0 rank 7 nranks 8 cudaDev 7 busId bd000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:113:666 [4] NCCL INFO comm 0x56001c653300 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:170:692 [5] NCCL INFO comm 0x56219299f4b0 rank 5 nranks 8 cudaDev 5 busId 90000 - Init COMPLETE
 msalehjahromi-torchrun-ftn-n62br:168:694 [4] NCCL INFO comm 0x55eb9df8b270 rank 4 nranks 8 cudaDev 4 busId 87000 - Init COMPLETE
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 2025-05-10 18:21:32,960 - INFO - using MLP layer as FFN
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])Found cls_token in weights with shape: torch.Size([1, 1, 768])
 
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 
 ==== Dataset Statistics ====
 Total samples: 43852
 Training samples: 32922
 Validation samples: 5460
 
 1-year-cancer:
   Train positive: 1242 (3.77%)
   Val positive: 186 (3.41%)
 
 2-year-cancer:
   Train positive: 1638 (4.98%)
   Val positive: 253 (4.63%)
 
 3-year-cancer:
   Train positive: 1970 (5.98%)
   Val positive: 312 (5.71%)
 
 4-year-cancer:
   Train positive: 2226 (6.76%)
   Val positive: 360 (6.59%)
 
 5-year-cancer:
   Train positive: 2436 (7.40%)
   Val positive: 402 (7.36%)
 
 6-year-cancer:
   Train positive: 2562 (7.78%)
   Val positive: 426 (7.80%)
 ============================
 
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 2025-05-10 18:21:33,784 - INFO - using MLP layer as FFN
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Total validation samples: 5460
 Created distributed validation loader, each rank processes ~645 samples
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 2025-05-10 18:21:34,434 - INFO - using MLP layer as FFN
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 2025-05-10 18:21:34,616 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:34,616 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:34,617 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 2025-05-10 18:21:34,620 - INFO - using MLP layer as FFN
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 2025-05-10 18:21:34,731 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:34,732 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:34,732 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:34,735 - INFO - using MLP layer as FFN
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])Found cls_token in weights with shape: torch.Size([1, 1, 768])
 
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 2025-05-10 18:21:39,553 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:39,553 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:39,553 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:39,556 - INFO - using MLP layer as FFN
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 Found cls_token in weights with shape: torch.Size([1, 1, 768])
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 2025-05-10 18:21:40,186 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:40,187 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:40,187 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:40,193 - INFO - using MLP layer as FFN
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 Verifying all parameters are on cuda:0
 All parameters successfully verified on cuda:0
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:826: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   f"storage size: {model_ct.cls_token.storage().size()}")
 Cls token shape after loading: torch.Size([1, 1, 768]), requires_grad: True, storage size: 768
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:817: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:  # Check if meta/empty
 2025-05-10 18:21:40,681 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:40,681 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:40,682 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:40,686 - INFO - using MLP layer as FFN
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182140.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 Verifying all parameters are on cuda:0
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 All parameters successfully verified on cuda:0
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 2025-05-10 18:21:41,227 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:41,227 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:41,227 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:41,232 - INFO - using MLP layer as FFN
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182141.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 2025-05-10 18:21:41,387 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:41,387 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:41,388 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:41,401 - INFO - using MLP layer as FFN
 2025-05-10 18:21:41,407 - INFO - DinoVisionTransformer parameters: 176 (LR: 1.0000000000000002e-06)
 2025-05-10 18:21:41,407 - INFO - Aggregator parameters: 26 (LR: 0.0001)
 2025-05-10 18:21:41,407 - INFO - Setting unfreeze_strategy to 'all' to avoid DDP synchronization issues
 2025-05-10 18:21:41,413 - INFO - using MLP layer as FFN
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182147.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182157.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182208.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182209.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182211.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py:116: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if hasattr(m, n) and getattr(m, n).storage().size() == 0:
 Will save metrics to: /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/training_metrics_nGPU_DDP_20250510_182215.jsonl
 Will save checkpoints to /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu/checkpoints
 
 Training Configuration:
 Max chunks per sample: 8
 Learning rate: 0.0001
 Number of tasks: 6
 Validation frequency: 100 steps
 Number of epochs: 50
 Warmup steps: 1000
 World size: 8
 Device: cuda
 
 Epoch 1: All parameters already unfrozen (strategy: all)
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 Traceback (most recent call last):
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 1061, in <module>
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 917, in main
     'final_metrics': {
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 474, in fit
     print(acc_string.rstrip(" | "))
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 209, in _train_step
     logits = self.model(chunks, spacing)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
     output = self._run_ddp_forward(*inputs, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
     return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/model_utils.py", line 297, in forward
     feats = torch.cat([self._chunk_embed(x[i]) for i in range(S)], dim=0)  # [S, 768]
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/model_utils.py", line 297, in <listcomp>
     feats = torch.cat([self._chunk_embed(x[i]) for i in range(S)], dim=0)  # [S, 768]
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/model_utils.py", line 287, in _chunk_embed
     return self.base(chunk.unsqueeze(0))       # → [1, 768]
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/models/vision_transformer.py", line 325, in forward
     ret = self.forward_features(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/models/vision_transformer.py", line 261, in forward_features
     x = blk(x)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/models/vision_transformer.py", line 40, in forward
     x = b(x)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py", line 254, in forward
     return super().forward(x_or_x_list)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py", line 113, in forward
     x = x + ffn_residual_func(x)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py", line 94, in ffn_residual_func
     return self.ls2(self.mlp(self.norm2(x)))
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/mlp.py", line 38, in forward
     x = self.fc2(x)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
     return F.linear(input, self.weight, self.bias)
 torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 39.38 GiB total capacity; 2.63 GiB already allocated; 8.44 MiB free; 2.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
 Traceback (most recent call last):
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 1061, in <module>
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 917, in main
     'final_metrics': {
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 474, in fit
     print(acc_string.rstrip(" | "))
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py", line 209, in _train_step
     logits = self.model(chunks, spacing)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
     output = self._run_ddp_forward(*inputs, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
     return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/model_utils.py", line 297, in forward
     feats = torch.cat([self._chunk_embed(x[i]) for i in range(S)], dim=0)  # [S, 768]
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/model_utils.py", line 297, in <listcomp>
     feats = torch.cat([self._chunk_embed(x[i]) for i in range(S)], dim=0)  # [S, 768]
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/model_utils.py", line 287, in _chunk_embed
     return self.base(chunk.unsqueeze(0))       # → [1, 768]
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/models/vision_transformer.py", line 325, in forward
     ret = self.forward_features(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/models/vision_transformer.py", line 261, in forward_features
     x = blk(x)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/models/vision_transformer.py", line 40, in forward
     x = b(x)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py", line 254, in forward
     return super().forward(x_or_x_list)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py", line 112, in forward
     x = x + attn_residual_func(x)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py", line 91, in attn_residual_func
     return self.ls1(self.attn(self.norm1(x)))
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py", line 80, in forward
     qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
     return forward_call(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
     return F.linear(input, self.weight, self.bias)
 RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 msalehjahromi-torchrun-ftn-n62br:109:754 [0] NCCL INFO [Service thread] Connection closed by localRank 0
 msalehjahromi-torchrun-ftn-n62br:109:109 [0] NCCL INFO comm 0x563208c2e960 rank 0 nranks 8 cudaDev 0 busId 7000 - Abort COMPLETE
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 msalehjahromi-torchrun-ftn-n62br:161:747 [0] NCCL INFO [Service thread] Connection closed by localRank 0
 msalehjahromi-torchrun-ftn-n62br:161:161 [0] NCCL INFO comm 0x564f11780f40 rank 0 nranks 8 cudaDev 0 busId 7000 - Abort COMPLETE
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 110 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 111 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 112 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 113 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 114 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 115 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 116 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 163 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 164 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 166 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 168 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 170 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 172 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 174 closing signal SIGTERM
 ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 109) of binary: /usr/bin/python3
 Traceback (most recent call last):
   File "/usr/local/bin/torchrun", line 8, in <module>
     sys.exit(main())
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
     return f(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
     run(args)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
     elastic_launch(
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
     return launch_agent(self._config, self._entrypoint, list(args))
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
     raise ChildFailedError(
 torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
 ============================================================
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py FAILED
 ------------------------------------------------------------
 Failures:
   <NO_OTHER_FAILURES>
 ------------------------------------------------------------
 Root Cause (first observed failure):
 [0]:
   time      : 2025-05-10_18:24:06
   host      : msalehjahromi-torchrun-ftn-n62br
   rank      : 0 (local_rank: 0)
   exitcode  : 1 (pid: 109)
   error_file: <N/A>
   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
 ============================================================
 ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 161) of binary: /usr/bin/python3
 Traceback (most recent call last):
   File "/usr/local/bin/torchrun", line 8, in <module>
     sys.exit(main())
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
     return f(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
     run(args)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
     elastic_launch(
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
     return launch_agent(self._config, self._entrypoint, list(args))
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
     raise ChildFailedError(
 torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
 ============================================================
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py FAILED
 ------------------------------------------------------------
 Failures:
   <NO_OTHER_FAILURES>
 ------------------------------------------------------------
 Root Cause (first observed failure):
 [0]:
   time      : 2025-05-10_18:24:06
   host      : msalehjahromi-torchrun-ftn-n62br
   rank      : 0 (local_rank: 0)
   exitcode  : 1 (pid: 161)
   error_file: <N/A>
   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
 ============================================================
 Traceback (most recent call last):
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_launcher.py", line 268, in <module>
     main(args) 
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_launcher.py", line 217, in main
     subprocess.run(torchrun_command, check=True)
   File "/usr/lib/python3.10/subprocess.py", line 526, in run
     raise CalledProcessError(retcode, process.args,
 subprocess.CalledProcessError: Command '['torchrun', '--nproc_per_node=8', '--master_port=52475', '/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py', '--csv', '/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv', '--accum-steps', '20', '--num-workers', '10', '--epochs', '50', '--lr', '0.0001', '--weight-decay', '0.0001', '--optimizer', 'adamw', '--num-attn-heads', '3', '--num-layers', '2', '--dropout', '0.3', '--unfreeze-strategy', 'all', '--output', '/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu', '--print-every', '50', '--val-every', '100', '--metrics-dir', '/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu']' returned non-zero exit status 1.
 Traceback (most recent call last):
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_launcher.py", line 268, in <module>
     main(args) 
   File "/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_launcher.py", line 217, in main
     subprocess.run(torchrun_command, check=True)
   File "/usr/lib/python3.10/subprocess.py", line 526, in run
     raise CalledProcessError(retcode, process.args,
 subprocess.CalledProcessError: Command '['torchrun', '--nproc_per_node=8', '--master_port=39995', '/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_full.py', '--csv', '/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv', '--accum-steps', '20', '--num-workers', '10', '--epochs', '50', '--lr', '0.0001', '--weight-decay', '0.0001', '--optimizer', 'adamw', '--num-attn-heads', '3', '--num-layers', '2', '--dropout', '0.3', '--unfreeze-strategy', 'all', '--output', '/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu', '--print-every', '50', '--val-every', '100', '--metrics-dir', '/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/metrics_multi_gpu']' returned non-zero exit status 1.
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   storage_data_ptr = tensors[0].storage().data_ptr()
 /rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
   if x.storage().data_ptr() != storage_data_ptr:
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 73 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 74 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 75 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 78 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 79 closing signal SIGTERM
 WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 80 closing signal SIGTERM
 ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 3 (pid: 76) of binary: /usr/bin/python3
 Traceback (most recent call last):
   File "/usr/local/bin/torchrun", line 8, in <module>
     sys.exit(main())
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
     return f(*args, **kwargs)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
     run(args)
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
     elastic_launch(
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
     return launch_agent(self._config, self._entrypoint, list(args))
   File "/rsrch1/ip/msalehjahromi/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
     raise ChildFailedError(
 torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
 ============================================================
 /rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/n_GPU_A100/2_run_fineTune_ddp_launcher.py FAILED
 ------------------------------------------------------------
 Failures:
 [1]:
   time      : 2025-05-10_18:24:10
   host      : msalehjahromi-torchrun-ftn-n62br
   rank      : 4 (local_rank: 4)
   exitcode  : 1 (pid: 77)
   error_file: <N/A>
   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
 ------------------------------------------------------------
 Root Cause (first observed failure):
 [0]:
   time      : 2025-05-10_18:24:10
   host      : msalehjahromi-torchrun-ftn-n62br
   rank      : 3 (local_rank: 3)
   exitcode  : 1 (pid: 76)
   error_file: <N/A>
   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
 ============================================================