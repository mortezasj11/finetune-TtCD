{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65c7bf0-590a-464c-8f4f-a5734d1dfd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in /opt/venv/jupyter/lib/python3.10/site-packages (5.3.2)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in /opt/venv/jupyter/lib/python3.10/site-packages (from nibabel) (6.5.2)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/venv/jupyter/lib/python3.10/site-packages (from nibabel) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20 in /opt/venv/jupyter/lib/python3.10/site-packages (from nibabel) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/venv/jupyter/lib/python3.10/site-packages (from nibabel) (4.12.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
      "Collecting torch==2.0.0\n",
      "  Using cached https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp310-cp310-linux_x86_64.whl (1843.9 MB)\n",
      "Collecting torchvision==0.15.0\n",
      "  Using cached https://download.pytorch.org/whl/cu117/torchvision-0.15.0%2Bcu117-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting torchmetrics==0.10.3\n",
      "  Using cached torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fvcore\n",
      "  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n",
      "Collecting iopath\n",
      "  Using cached iopath-0.1.10-py3-none-any.whl\n",
      "Collecting filelock (from torch==2.0.0)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/venv/jupyter/lib/python3.10/site-packages (from torch==2.0.0) (4.12.2)\n",
      "Collecting sympy (from torch==2.0.0)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/venv/jupyter/lib/python3.10/site-packages (from torch==2.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/jupyter/lib/python3.10/site-packages (from torch==2.0.0) (3.1.6)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: numpy in /opt/venv/jupyter/lib/python3.10/site-packages (from torchvision==0.15.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/venv/jupyter/lib/python3.10/site-packages (from torchvision==0.15.0) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/venv/jupyter/lib/python3.10/site-packages (from torchvision==0.15.0) (11.1.0)\n",
      "Requirement already satisfied: packaging in /opt/venv/jupyter/lib/python3.10/site-packages (from torchmetrics==0.10.3) (24.2)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0)\n",
      "  Using cached cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
      "  Using cached lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/venv/jupyter/lib/python3.10/site-packages (from omegaconf) (6.0.2)\n",
      "Collecting yacs>=0.1.6 (from fvcore)\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting tqdm (from fvcore)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting termcolor>=1.1 (from fvcore)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tabulate (from fvcore)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting portalocker (from iopath)\n",
      "  Using cached portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/jupyter/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/venv/jupyter/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/jupyter/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/venv/jupyter/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/jupyter/lib/python3.10/site-packages (from requests->torchvision==0.15.0) (2025.1.31)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.0)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
      "Using cached lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Installing collected packages: mpmath, lit, antlr4-python3-runtime, yacs, tqdm, termcolor, tabulate, sympy, portalocker, omegaconf, filelock, cmake, iopath, fvcore, triton, torch, torchvision, torchmetrics\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 cmake-4.0.0 filelock-3.18.0 fvcore-0.1.5.post20221221 iopath-0.1.10 lit-18.1.8 mpmath-1.3.0 omegaconf-2.3.0 portalocker-3.1.1 sympy-1.13.3 tabulate-0.9.0 termcolor-3.0.1 torch-2.0.0+cu117 torchmetrics-0.10.3 torchvision-0.15.0+cu117 tqdm-4.67.1 triton-2.0.0 yacs-0.1.8\n",
      "Requirement already satisfied: numpy<2.0 in /opt/venv/jupyter/lib/python3.10/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!pip install nibabel\n",
    "!pip  install --extra-index-url https://download.pytorch.org/whl/cu117 torch==2.0.0 torchvision==0.15.0 omegaconf torchmetrics==0.10.3 fvcore iopath \n",
    "#!pip  install --extra-index-url https://download.pytorch.org/whl/cu117 torch==2.0.0 torchvision==0.15.0 omegaconf torchmetrics==0.10.3 fvcore iopath xformers==0.0.18 submitit\n",
    "!pip install \"numpy<2.0\"\n",
    "#xformers should not be installed!!!!!!!\n",
    "#!pip uninstall xformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195ae7f4-594c-4ded-b374-0c9833344af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original validation set size: (5460, 21)\n",
      "\n",
      "Before balancing:\n",
      "Positive samples: 272\n",
      "Negative samples: 1816\n",
      "\n",
      "After balancing:\n",
      "Balanced validation set shape: (544, 21)\n",
      "\n",
      "Final shapes:\n",
      "New validation set shape: (544, 21)\n",
      "Total dataset shape: (38936, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/rsrch1/ip/msalehjahromi/codes/dinov2-torchrun-dataloader6/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['teacher'])\n",
      "Using CUDA device: 0\n",
      "Class weights: tensor([33.4192, 19.4125, 14.0958, 11.3240,  7.4886,  4.0204])\n",
      "Using device: cuda:0\n",
      "\n",
      ">>> Epoch 1/10\n",
      "Epoch 1: Base model is fully frozen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/finetuneA100_gradual_transformer.py\", line 603, in <module>\n",
      "    main(args) \n",
      "  File \"/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/finetuneA100_gradual_transformer.py\", line 565, in main\n",
      "    trainer.fit(train_loader, val_loader, \n",
      "  File \"/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/finetuneA100_gradual_transformer.py\", line 362, in fit\n",
      "    for step, (chunks, labels, mask) in enumerate(train_loader, 1):\n",
      "  File \"/opt/venv/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/venv/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/venv/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/opt/venv/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m df_new\u001b[38;5;241m.\u001b[39mto_csv(temp_csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Run the training script with the balanced validation set\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/finetuneA100_gradual_transformer.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_csv_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--accum-steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--cuda-id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/local/bin/cpython-3.10.16-linux-x86_64-gnu/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare the balanced validation set\n",
    "df = pd.read_csv(\"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_.csv\")\n",
    "\n",
    "# Print original validation set size\n",
    "print(\"Original validation set size:\", df[df[\"split\"]==\"val\"].shape)\n",
    "\n",
    "val_df = df[df.split == 'val'].copy()\n",
    "val_df = val_df[val_df.file_path.notna()].reset_index(drop=True)\n",
    "\n",
    "# Get positive and negative samples for 6-year-cancer\n",
    "pos_samples = val_df[val_df['6-year-cancer'] == 1]\n",
    "neg_samples = val_df[val_df['6-year-cancer'] == 0]\n",
    "\n",
    "print(\"\\nBefore balancing:\")\n",
    "print(f\"Positive samples: {len(pos_samples)}\")\n",
    "print(f\"Negative samples: {len(neg_samples)}\")\n",
    "\n",
    "# Calculate sizes for balanced set\n",
    "n_pos = len(pos_samples)\n",
    "n_neg = len(neg_samples)\n",
    "target_size = min(n_pos, n_neg)\n",
    "\n",
    "# Sample equally from positive and negative\n",
    "balanced_pos = pos_samples.sample(n=target_size, random_state=42)\n",
    "balanced_neg = neg_samples.sample(n=target_size, random_state=42)\n",
    "\n",
    "# Combine balanced samples\n",
    "balanced_val_df = pd.concat([balanced_pos, balanced_neg]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAfter balancing:\")\n",
    "print(f\"Balanced validation set shape: {balanced_val_df.shape}\")\n",
    "\n",
    "# Create new dataframe correctly\n",
    "df_new = df.copy()\n",
    "# Remove all validation samples\n",
    "df_new = df_new[df_new.split != 'val']\n",
    "# Add balanced validation samples\n",
    "balanced_val_df['split'] = 'val'  # Ensure split column is set\n",
    "df_new = pd.concat([df_new, balanced_val_df], ignore_index=True)\n",
    "\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"New validation set shape: {df_new[df_new['split']=='val'].shape}\")\n",
    "print(f\"Total dataset shape: {df_new.shape}\")\n",
    "\n",
    "# Save the balanced validation set\n",
    "temp_csv_path = \"/rsrch1/ip/msalehjahromi/codes/FineTune/nlst_event_train_val_test_balanced.csv\"\n",
    "df_new.to_csv(temp_csv_path, index=False)\n",
    "\n",
    "# Run the training script with the balanced validation set\n",
    "subprocess.run([\n",
    "    \"python3\", \n",
    "    \"/rsrch1/ip/msalehjahromi/codes/FineTune/multiGPU/finetuneA100_gradual_transformer.py\",\n",
    "    \"--csv\", temp_csv_path,\n",
    "    \"--accum-steps\", \"10\",\n",
    "    \"--cuda-id\", \"0\",\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82519829-316d-42a1-b9c0-b05669de9465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
